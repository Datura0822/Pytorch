{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[[[-0.0213, -0.2633,  0.2114],\n",
      "          [-0.1554, -0.2324, -0.1086],\n",
      "          [-0.0581,  0.0548, -0.3330]]],\n",
      "\n",
      "\n",
      "        [[[-0.0444,  0.3029, -0.1271],\n",
      "          [ 0.3239,  0.2314,  0.3233],\n",
      "          [ 0.0360, -0.0179,  0.2283]]],\n",
      "\n",
      "\n",
      "        [[[-0.2831,  0.1527,  0.0164],\n",
      "          [-0.1105, -0.2142,  0.2372],\n",
      "          [ 0.0442, -0.1857, -0.1708]]],\n",
      "\n",
      "\n",
      "        [[[-0.2011,  0.1630,  0.2372],\n",
      "          [ 0.1289,  0.1390, -0.0401],\n",
      "          [-0.2539,  0.0615,  0.3332]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1120,  0.2750,  0.2303],\n",
      "          [-0.1529,  0.1545, -0.1387],\n",
      "          [-0.2525, -0.0991,  0.1354]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0675, -0.0547, -0.1956],\n",
      "          [ 0.2077,  0.1006, -0.2865],\n",
      "          [-0.1597, -0.1198, -0.3193]]]], device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([ 0.0287, -0.3297,  0.1459, -0.0533,  0.2045, -0.3245], device='cuda:0',\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "module = model.conv1\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Pruning a Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.random_unstructured(module, name=\"weight\", amount=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([ 0.0287, -0.3297,  0.1459, -0.0533,  0.2045, -0.3245], device='cuda:0',\n",
      "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[[[-0.0213, -0.2633,  0.2114],\n",
      "          [-0.1554, -0.2324, -0.1086],\n",
      "          [-0.0581,  0.0548, -0.3330]]],\n",
      "\n",
      "\n",
      "        [[[-0.0444,  0.3029, -0.1271],\n",
      "          [ 0.3239,  0.2314,  0.3233],\n",
      "          [ 0.0360, -0.0179,  0.2283]]],\n",
      "\n",
      "\n",
      "        [[[-0.2831,  0.1527,  0.0164],\n",
      "          [-0.1105, -0.2142,  0.2372],\n",
      "          [ 0.0442, -0.1857, -0.1708]]],\n",
      "\n",
      "\n",
      "        [[[-0.2011,  0.1630,  0.2372],\n",
      "          [ 0.1289,  0.1390, -0.0401],\n",
      "          [-0.2539,  0.0615,  0.3332]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1120,  0.2750,  0.2303],\n",
      "          [-0.1529,  0.1545, -0.1387],\n",
      "          [-0.2525, -0.0991,  0.1354]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0675, -0.0547, -0.1956],\n",
      "          [ 0.2077,  0.1006, -0.2865],\n",
      "          [-0.1597, -0.1198, -0.3193]]]], device='cuda:0', requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[[[1., 0., 1.],\n",
      "          [0., 1., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 0.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.],\n",
      "          [1., 0., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 1.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 0., 0.]]]], device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.0213, -0.0000,  0.2114],\n",
      "          [-0.0000, -0.2324, -0.1086],\n",
      "          [-0.0581,  0.0548, -0.3330]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.3029, -0.0000],\n",
      "          [ 0.3239,  0.2314,  0.3233],\n",
      "          [ 0.0360, -0.0000,  0.2283]]],\n",
      "\n",
      "\n",
      "        [[[-0.2831,  0.1527,  0.0000],\n",
      "          [-0.1105, -0.0000,  0.2372],\n",
      "          [ 0.0442, -0.1857, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.2011,  0.0000,  0.2372],\n",
      "          [ 0.1289,  0.1390, -0.0000],\n",
      "          [-0.2539,  0.0615,  0.3332]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.2750,  0.2303],\n",
      "          [-0.1529,  0.1545, -0.1387],\n",
      "          [-0.2525, -0.0000,  0.1354]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0675, -0.0000, -0.0000],\n",
      "          [ 0.2077,  0.1006, -0.2865],\n",
      "          [-0.1597, -0.0000, -0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(0, <torch.nn.utils.prune.RandomUnstructured object at 0x00000184C2325A90>)])\n"
     ]
    }
   ],
   "source": [
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.l1_unstructured(module, name=\"bias\", amount=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_orig', Parameter containing:\n",
      "tensor([[[[-0.0213, -0.2633,  0.2114],\n",
      "          [-0.1554, -0.2324, -0.1086],\n",
      "          [-0.0581,  0.0548, -0.3330]]],\n",
      "\n",
      "\n",
      "        [[[-0.0444,  0.3029, -0.1271],\n",
      "          [ 0.3239,  0.2314,  0.3233],\n",
      "          [ 0.0360, -0.0179,  0.2283]]],\n",
      "\n",
      "\n",
      "        [[[-0.2831,  0.1527,  0.0164],\n",
      "          [-0.1105, -0.2142,  0.2372],\n",
      "          [ 0.0442, -0.1857, -0.1708]]],\n",
      "\n",
      "\n",
      "        [[[-0.2011,  0.1630,  0.2372],\n",
      "          [ 0.1289,  0.1390, -0.0401],\n",
      "          [-0.2539,  0.0615,  0.3332]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1120,  0.2750,  0.2303],\n",
      "          [-0.1529,  0.1545, -0.1387],\n",
      "          [-0.2525, -0.0991,  0.1354]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0675, -0.0547, -0.1956],\n",
      "          [ 0.2077,  0.1006, -0.2865],\n",
      "          [-0.1597, -0.1198, -0.3193]]]], device='cuda:0', requires_grad=True)), ('bias_orig', Parameter containing:\n",
      "tensor([ 0.0287, -0.3297,  0.1459, -0.0533,  0.2045, -0.3245], device='cuda:0',\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[[[1., 0., 1.],\n",
      "          [0., 1., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 0.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.],\n",
      "          [1., 0., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 1.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 0., 0.]]]], device='cuda:0')), ('bias_mask', tensor([0., 1., 0., 0., 1., 1.], device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000, -0.3297,  0.0000, -0.0000,  0.2045, -0.3245], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(0, <torch.nn.utils.prune.RandomUnstructured object at 0x00000184C2325A90>), (1, <torch.nn.utils.prune.L1Unstructured object at 0x00000184C232D320>)])\n"
     ]
    }
   ],
   "source": [
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Iterative Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同一个模块中的同一个参数可以进行多次修剪，各种修剪调用的效果等于一系列应用的各种掩码的组合。新掩码与旧掩码的组合由PruningContainer的compute_mask方法处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.3029, -0.0000],\n",
      "          [ 0.3239,  0.2314,  0.3233],\n",
      "          [ 0.0360, -0.0000,  0.2283]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.2011,  0.0000,  0.2372],\n",
      "          [ 0.1289,  0.1390, -0.0000],\n",
      "          [-0.2539,  0.0615,  0.3332]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.2750,  0.2303],\n",
      "          [-0.1529,  0.1545, -0.1387],\n",
      "          [-0.2525, -0.0000,  0.1354]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prune.ln_structured(module, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "\n",
    "# As we can verify, this will zero out all the connections corresponding to\n",
    "# 50% (3 out of 6) of the channels, while preserving the action of the\n",
    "# previous mask.\n",
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<torch.nn.utils.prune.RandomUnstructured object at 0x00000184C2325A90>, <torch.nn.utils.prune.LnStructured object at 0x00000184C2395128>]\n"
     ]
    }
   ],
   "source": [
    "for hook in module._forward_pre_hooks.values():\n",
    "    if hook._tensor_name == \"weight\":  # select out the correct hook\n",
    "        break\n",
    "\n",
    "print(list(hook))  # pruning history in the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove pruning re-parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_orig', Parameter containing:\n",
      "tensor([[[[-0.0213, -0.2633,  0.2114],\n",
      "          [-0.1554, -0.2324, -0.1086],\n",
      "          [-0.0581,  0.0548, -0.3330]]],\n",
      "\n",
      "\n",
      "        [[[-0.0444,  0.3029, -0.1271],\n",
      "          [ 0.3239,  0.2314,  0.3233],\n",
      "          [ 0.0360, -0.0179,  0.2283]]],\n",
      "\n",
      "\n",
      "        [[[-0.2831,  0.1527,  0.0164],\n",
      "          [-0.1105, -0.2142,  0.2372],\n",
      "          [ 0.0442, -0.1857, -0.1708]]],\n",
      "\n",
      "\n",
      "        [[[-0.2011,  0.1630,  0.2372],\n",
      "          [ 0.1289,  0.1390, -0.0401],\n",
      "          [-0.2539,  0.0615,  0.3332]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1120,  0.2750,  0.2303],\n",
      "          [-0.1529,  0.1545, -0.1387],\n",
      "          [-0.2525, -0.0991,  0.1354]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0675, -0.0547, -0.1956],\n",
      "          [ 0.2077,  0.1006, -0.2865],\n",
      "          [-0.1597, -0.1198, -0.3193]]]], device='cuda:0', requires_grad=True)), ('bias_orig', Parameter containing:\n",
      "tensor([ 0.0287, -0.3297,  0.1459, -0.0533,  0.2045, -0.3245], device='cuda:0',\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 0.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 1.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]], device='cuda:0')), ('bias_mask', tensor([0., 1., 0., 0., 1., 1.], device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.3029, -0.0000],\n",
      "          [ 0.3239,  0.2314,  0.3233],\n",
      "          [ 0.0360, -0.0000,  0.2283]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.2011,  0.0000,  0.2372],\n",
      "          [ 0.1289,  0.1390, -0.0000],\n",
      "          [-0.2539,  0.0615,  0.3332]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.2750,  0.2303],\n",
      "          [-0.1529,  0.1545, -0.1387],\n",
      "          [-0.2525, -0.0000,  0.1354]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias_orig', Parameter containing:\n",
      "tensor([ 0.0287, -0.3297,  0.1459, -0.0533,  0.2045, -0.3245], device='cuda:0',\n",
      "       requires_grad=True)), ('weight', Parameter containing:\n",
      "tensor([[[[-0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.3029, -0.0000],\n",
      "          [ 0.3239,  0.2314,  0.3233],\n",
      "          [ 0.0360, -0.0000,  0.2283]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.2011,  0.0000,  0.2372],\n",
      "          [ 0.1289,  0.1390, -0.0000],\n",
      "          [-0.2539,  0.0615,  0.3332]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.2750,  0.2303],\n",
      "          [-0.1529,  0.1545, -0.1387],\n",
      "          [-0.2525, -0.0000,  0.1354]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]]]], device='cuda:0', requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "prune.remove(module, 'weight')\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias_mask', tensor([0., 1., 0., 0., 1., 1.], device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning multiple parameters in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc3.weight_mask'])\n"
     ]
    }
   ],
   "source": [
    "new_model = LeNet()\n",
    "for name, module in new_model.named_modules():\n",
    "    # prune 20% of connections in all 2D-conv layers\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.2)\n",
    "    # prune 40% of connections in all linear layers\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.4)\n",
    "\n",
    "print(dict(new_model.named_buffers()).keys())  # to verify that all masks exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "\n",
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.conv2, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    (model.fc2, 'weight'),\n",
    "    (model.fc3, 'weight'),\n",
    ")\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1.weight: 1.85%\n",
      "Sparsity in conv2.weight: 9.61%\n",
      "Sparsity in fc1.weight: 22.04%\n",
      "Sparsity in fc2.weight: 12.15%\n",
      "Sparsity in fc3.weight: 9.40%\n",
      "Global sparsity: 20.00%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.conv1.weight == 0))\n",
    "        / float(model.conv1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.conv2.weight == 0))\n",
    "        / float(model.conv2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc1.weight == 0))\n",
    "        / float(model.fc1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc2.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc2.weight == 0))\n",
    "        / float(model.fc2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc3.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc3.weight == 0))\n",
    "        / float(model.fc3.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "            + torch.sum(model.fc1.weight == 0)\n",
    "            + torch.sum(model.fc2.weight == 0)\n",
    "            + torch.sum(model.fc3.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "            + model.fc1.weight.nelement()\n",
    "            + model.fc2.weight.nelement()\n",
    "            + model.fc3.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending torch.nn.utils.prune with custom pruning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FooBarPruningMethod(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = default_mask.clone()\n",
    "        mask.view(-1)[::2] = 0\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foobar_unstructured(module, name):\n",
    "    \"\"\"Prunes tensor corresponding to parameter called `name` in `module`\n",
    "    by removing every other entry in the tensors.\n",
    "    Modifies module in place (and also return the modified module)\n",
    "    by:\n",
    "    1) adding a named buffer called `name+'_mask'` corresponding to the\n",
    "    binary mask applied to the parameter `name` by the pruning method.\n",
    "    The parameter `name` is replaced by its pruned version, while the\n",
    "    original (unpruned) parameter is stored in a new parameter named\n",
    "    `name+'_orig'`.\n",
    "\n",
    "    Args:\n",
    "        module (nn.Module): module containing the tensor to prune\n",
    "        name (string): parameter name within `module` on which pruning\n",
    "                will act.\n",
    "\n",
    "    Returns:\n",
    "        module (nn.Module): modified (i.e. pruned) version of the input\n",
    "            module\n",
    "\n",
    "    Examples:\n",
    "        >>> m = nn.Linear(3, 4)\n",
    "        >>> foobar_unstructured(m, name='bias')\n",
    "    \"\"\"\n",
    "    FooBarPruningMethod.apply(module, name)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "foobar_unstructured(model.fc3, name='bias')\n",
    "\n",
    "print(model.fc3.bias_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
